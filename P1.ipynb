{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "#!pip install --upgrade pip\n",
    "#!pip install imageio_ffmpeg\n",
    "#!pip install moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def caliberation(path, file, nx, ny, size):\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "    objpoints = [] \n",
    "    imgpoints = []\n",
    "    \n",
    "    images = glob.glob('./'+path+'/'+file+'*'+'.jpg')\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        \n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, size, None, None)\n",
    "    \n",
    "    return mtx, dist\n",
    "\n",
    "\n",
    "\n",
    "def undistort(image, mtx, dist):\n",
    "    image = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "mtx, dist = caliberation('camera_cal', 'calibration', 9, 6, (720, 1280))\n",
    "checker_dist = mpimg.imread(\"./camera_cal/calibration2.jpg\")\n",
    "checker_undist = undistort(checker_dist, mtx, dist)\n",
    "\n",
    "\n",
    "\n",
    "f, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(12, 18))\n",
    "ax1.imshow(checker_dist)\n",
    "ax1.set_title('Original', fontsize=15)\n",
    "ax2.imshow(checker_undist)\n",
    "ax2.set_title('Undistorted', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh_min=0, thresh_max = 255):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "    \n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    \n",
    "    grad_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    \n",
    "    return grad_binary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(30, 100)):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    \n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return mag_binary\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    \n",
    "    return dir_binary\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def hls_thresh(img, thresh=(100, 255)):\n",
    "    \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  combine_threshold_gradient(image):\n",
    "    \n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh_min=50, thresh_max = 255)\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=3, thresh_min=50, thresh_max = 255)\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=3, mag_thresh=(50, 255))\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=9, thresh=(0, np.pi/2))\n",
    "    hls_bin = hls_thresh(image, thresh=(170, 255))\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))| hls_bin == 1] = 1\n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def channel_Isolate(image,channel):\n",
    "    ## Takes in only RBG images\n",
    "    if (channel == 'R'):\n",
    "        return image[:,:,0]\n",
    "    \n",
    "    elif (channel == 'G'):\n",
    "        return image[:,:,1]\n",
    "    \n",
    "    elif (channel == 'B'):\n",
    "        return image[:,:,2]\n",
    "    \n",
    "    elif (channel == 'H'):\n",
    "        HSV = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        return HSV[:,:,0]\n",
    "    \n",
    "    elif (channel == 'S'):\n",
    "        HSV = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        return HSV[:,:,1]\n",
    "        \n",
    "    elif (channel == 'V'):\n",
    "        HSV = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        return HSV[:,:,2]\n",
    "        \n",
    "    elif (channel == 'L'):\n",
    "        HLS = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        return HLS[:,:,1]\n",
    "    \n",
    "    elif (channel == 'Cb'):\n",
    "        YCrCb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        return YCrCb[:,:,2]\n",
    "    \n",
    "    elif (channel == 'U'):\n",
    "        LUV = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "        return LUV[:,:,2]\n",
    "    \n",
    "    else:\n",
    "        raise Error(\"Channel must be either R, G, B, H, S, V, L, Cb, U\")\n",
    "    \n",
    "def threshold_Channel(channel,thresh):\n",
    "    retval, binary = cv2.threshold(channel.astype('uint8'), thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(undist,src,dst,img_size):\n",
    "        \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    \n",
    "    return warped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_lines_pixels(img):\n",
    "    \n",
    "    right_side_x = []\n",
    "    right_side_y = []\n",
    "    left_side_x = []\n",
    "    left_side_y = []  \n",
    "    \n",
    "    past_cord = 0\n",
    "    \n",
    "    # right side\n",
    "    for i in reversed(range(10,100)):\n",
    "        histogram = np.sum(img[i*img.shape[0]/100:(i+1)*img.shape[0]/100,img.shape[1]/2:], axis=0) \n",
    "        xcord = int(np.argmax(histogram)) + 640\n",
    "        ycord = int(i*img.shape[0]/100)\n",
    "        if (i == 50):\n",
    "            right_lane_dp = (xcord)\n",
    "        if (ycord == 0 or xcord == 0):\n",
    "            pass\n",
    "        elif (abs(xcord-past_cord) > 100 and not(i == 99) and not( past_cord == 0)):\n",
    "            pass\n",
    "        elif (xcord == 640):\n",
    "            pass\n",
    "        else:\n",
    "            right_side_x.append(xcord)\n",
    "            right_side_y.append(ycord)\n",
    "            past_cord = xcord\n",
    "\n",
    "    past_cord = 0\n",
    "    # left side\n",
    "    for i in reversed(range(10,100)):\n",
    "        histogram = np.sum(img[i*img.shape[0]/100:(i+1)*img.shape[0]/100,:img.shape[1]/2], axis=0)\n",
    "        xcord = int(np.argmax(histogram))\n",
    "        ycord = int(i*img.shape[0]/100)\n",
    "        if (i == 50):\n",
    "            left_lane_dp = (xcord)\n",
    "        if (ycord == 0 or xcord == 0):\n",
    "            pass\n",
    "        elif (abs(xcord-past_cord) > 100 and not(i == 99) and not(past_cord == 0)):\n",
    "            pass\n",
    "        else:\n",
    "            left_side_x.append(xcord)\n",
    "            left_side_y.append(ycord)\n",
    "            past_cord = xcord\n",
    "    \n",
    "    left_line =  (left_side_x,left_side_y)\n",
    "    right_line = (right_side_x,right_side_y)\n",
    "    \n",
    "    left_line =  (left_line[0][1:(len(left_line[0])-1)],left_line[1][1:(len(left_line[1])-1)])\n",
    "    right_line = (right_line[0][1:(len(right_line[0])-1)],right_line[1][1:(len(right_line[1])-1)])\n",
    "    \n",
    "    lane_middle = int((right_lane_dp - left_lane_dp)/2.)+left_lane_dp\n",
    "    \n",
    "    if (lane_middle-640 > 0):\n",
    "        leng = 3.66/2\n",
    "        mag = ((lane_middle-640)/640.*leng)\n",
    "        head = (\"Right\",mag)\n",
    "    else:\n",
    "        leng = 3.66/2.\n",
    "        mag = ((lane_middle-640)/640.*leng)*-1\n",
    "        head = (\"Left\",mag)\n",
    "\n",
    "    \n",
    "    return left_line, right_line, head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lane_curve(left_line,right_line):\n",
    "    \n",
    "    degree_fit = 2\n",
    "    \n",
    "    fit_left = np.polyfit(left_line[1], left_line[0], degree_fit)\n",
    "    \n",
    "    fit_right = np.polyfit(right_line[1], right_line[0], degree_fit)\n",
    "    \n",
    "    x = [x * (3.7/700.) for x in left_line[0]]\n",
    "    y = [x * (30/720.) for x in left_line[1]]\n",
    "    \n",
    "    curve = np.polyfit(y, x, degree_fit)\n",
    "           \n",
    "    return fit_left, fit_right, curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lane_Area(undist, fit_left, fit_right, trans, src, dst, img_size, curve):\n",
    "    \n",
    "    global left_points,right_points\n",
    "    \n",
    "    left_points  = []\n",
    "    right_points = []\n",
    "\n",
    "    left = np.poly1d(fit_left)\n",
    "    right = np.poly1d(fit_right)\n",
    "\n",
    "    rad_curve = ((1 + (2*curve[0]*710/2 + curve[1])**2)**1.5)/np.absolute(2*curve[0])  \n",
    " \n",
    "    for i in range(100,710,2):\n",
    "        if (int(left(i)<0)):\n",
    "            pass\n",
    "        else:\n",
    "            left_points.append([int(left(i)),i])\n",
    "\n",
    "    for i in range(100,710,2):\n",
    "        if (int(right(i)<0)):\n",
    "            pass\n",
    "        else:\n",
    "            right_points.append([int(right(i)),i])\n",
    "\n",
    "    \n",
    "    polygon_points = right_points + list(reversed(left_points))\n",
    "    polygon_points = np.array(polygon_points)\n",
    "\n",
    "    \n",
    "    overlay = np.zeros_like(trans)\n",
    "    trans_image = cv2.fillPoly(overlay, [polygon_points], (0,255,0) )\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(dst, src)\n",
    "    unwarped = cv2.warpPerspective(trans_image, M, img_size)\n",
    "    \n",
    "    area = cv2.contourArea(polygon_points)\n",
    "    \n",
    "    return unwarped, area, rad_curve, polygon_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(image,mtx, dist):\n",
    "    global polygon, area, left, right, last, frame_count, Head_b, rad_curve_b, vehicle_count, IMAGE\n",
    "    \n",
    "        \n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    src =  np.float32([[250,700],[1200,700],[550,450],[750,450]])\n",
    "    dst = np.float32([[250,700],[1200,700],[300,50],[1000,50]])\n",
    "    \n",
    "    \n",
    "    undist = undistort(image, mtx, dist)\n",
    "    trans = transform(undist,src,dst,img_size)\n",
    "    \n",
    "    red_threshed = threshold_Channel(channel_Isolate(trans,'R'),(220,255))\n",
    "    V_threshed = threshold_Channel(channel_Isolate(trans,'V'),(220,255))\n",
    "    HSV = cv2.cvtColor(trans, cv2.COLOR_RGB2HSV)\n",
    "    yellow = cv2.inRange(HSV, (20, 100, 100), (50, 255, 255))\n",
    "    sensitivity_1 = 68\n",
    "    white = cv2.inRange(HSV, (0,0,255-sensitivity_1), (255,20,255))\n",
    "    sensitivity_2 = 60\n",
    "    HSL = cv2.cvtColor(trans, cv2.COLOR_RGB2HLS)\n",
    "    white_2 = cv2.inRange(HSL, (0,255-sensitivity_2,0), (255,255,sensitivity_2))\n",
    "    white_3 = cv2.inRange(trans, (200,200,200), (255,255,255))\n",
    "    bit_image = red_threshed | V_threshed | yellow | white | white_2 | white_3\n",
    "    \n",
    "    #bit_image =combine_threshold_gradient(trans)\n",
    "    \n",
    "    left_line, right_line, head = find_lines_pixels(bit_image)\n",
    "    \n",
    "    fit_left, fit_right, curve = lane_curve(left_line,right_line)\n",
    "    \n",
    "    unwarped, area, rad_curve, polygon_points = lane_Area(undist,fit_left, fit_right, trans, src, dst, img_size, curve)\n",
    "    \n",
    "    a = polygon_points\n",
    "    b = polygon_points\n",
    "    \n",
    "    ret = cv2.matchShapes(a, b, 1, 0.0)\n",
    "    original = undist.copy()\n",
    "    \n",
    "    polygon = unwarped\n",
    "    Head_b = head\n",
    "        \n",
    "    result = cv2.addWeighted(undist, 1, unwarped, 0.3, 0)\n",
    "    \n",
    "    original[475:720] = result[475:720]\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    \n",
    "    text = Head_b[0]\n",
    "    cv2.putText(original,text , (256,71), font, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "    dist = math.ceil(Head_b[1]*100)/100\n",
    "    cv2.putText(original,str(dist) , (181,71), font, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "    rad_curve = math.ceil(rad_curve*100)/100\n",
    "    cv2.putText(original,str(rad_curve) , (244,95), font, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    return original\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "directory = 'camera_cal'\n",
    "filename = 'calibration'\n",
    "nx = 9 \n",
    "ny = 6\n",
    "cal_img_size = (720, 1280)\n",
    "\n",
    "\n",
    "mtx, dist = caliberation(directory, filename, nx, ny, cal_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "image_1 = mpimg.imread(\"./test_images/test1.jpg\")\n",
    "Image_1 = pipeline(image_1, mtx, dist)\n",
    "image_2 = mpimg.imread(\"./test_images/test2.jpg\")\n",
    "Image_2 = pipeline(image_2, mtx, dist)\n",
    "image_3 = mpimg.imread(\"./test_images/test3.jpg\")\n",
    "Image_3 = pipeline(image_3, mtx, dist)\n",
    "image_4 = mpimg.imread(\"./test_images/test4.jpg\")\n",
    "Image_4 = pipeline(image_4, mtx, dist)\n",
    "image_5 = mpimg.imread(\"./test_images/test5.jpg\")\n",
    "Image_5 = pipeline(image_5, mtx, dist)\n",
    "image_6 = mpimg.imread(\"./test_images/test6.jpg\")\n",
    "Image_6 = pipeline(image_6, mtx, dist)\n",
    "\n",
    "mpimg.imsave(\"./output_images/Itest1.jpg\", Image_1)\n",
    "mpimg.imsave(\"./output_images/Itest2.jpg\", Image_1)\n",
    "mpimg.imsave(\"./output_images/Itest3.jpg\", Image_1)\n",
    "mpimg.imsave(\"./output_images/Itest4.jpg\", Image_1)\n",
    "mpimg.imsave(\"./output_images/Itest5.jpg\", Image_1)\n",
    "mpimg.imsave(\"./output_images/Itest6.jpg\", Image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = 'challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "clip = clip1.fl_image(lambda img: pipeline(img, mtx, dist, dash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
